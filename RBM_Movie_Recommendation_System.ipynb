{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "###### Importing the Libraries"
      ],
      "metadata": {
        "id": "AmRsrtrtd4t0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "P6QHwwfAcf95"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "from torch.autograd import Variable"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Load the Dataset"
      ],
      "metadata": {
        "id": "zO_K9SKyeBqF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "movies = pd.read_csv('movies.dat', sep='::', header=None, engine='python', encoding='Latin-1')\n",
        "users = pd.read_csv('users.dat', sep='::', header=None, engine='python', encoding='Latin-1')\n",
        "ratings = pd.read_csv('ratings.dat', sep='::', header=None, engine='python', encoding='Latin-1')"
      ],
      "metadata": {
        "id": "RPo_rOqad-6y"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Preparing the Training set and Test set"
      ],
      "metadata": {
        "id": "qagAOj02eUJ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_set = pd.read_csv('u1.base', delimiter='\\t')\n",
        "training_set = np.array(training_set, dtype='int')\n",
        "test_set = pd.read_csv('u1.test', delimiter='\\t')\n",
        "test_set = np.array(test_set, dtype='int')"
      ],
      "metadata": {
        "id": "TdJ3X0qyeVLw"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Getting the number of users and movies"
      ],
      "metadata": {
        "id": "VkGHt6WoeYJr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nb_users = int(max(max(training_set[:, 0]), max(test_set[:, 0])))\n",
        "nb_movies = int(max(max(training_set[:, 1]), max(test_set[:, 1])))"
      ],
      "metadata": {
        "id": "ClL_wZ6Iea0Y"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Converting the data into an array with users in lines and movies in columns"
      ],
      "metadata": {
        "id": "1mcb2Ujued1p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convert(data):\n",
        "  new_data = []\n",
        "  for id_users in range(1, nb_users + 1):\n",
        "      id_movies = data[:, 1][data[:, 0] == id_users]\n",
        "      id_ratings = data[:, 2][data[:, 0] == id_users]\n",
        "      ratings = np.zeros(nb_movies)\n",
        "      ratings[id_movies - 1] = id_ratings\n",
        "      new_data.append(list(ratings))\n",
        "  return new_data\n",
        "\n",
        "training_set = convert(training_set)\n",
        "test_set = convert(test_set)"
      ],
      "metadata": {
        "id": "2A5VB_4hehW4"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Converting the data into Torch tensors"
      ],
      "metadata": {
        "id": "BcPSfWj4ekDy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_set = torch.FloatTensor(training_set)\n",
        "test_set = torch.FloatTensor(test_set)"
      ],
      "metadata": {
        "id": "czCYfLinemqf"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Converting the ratings into binary 1 (liked) or 0 (Not liked)"
      ],
      "metadata": {
        "id": "Id5RJy2PeqM9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_set[training_set == 0] = -1\n",
        "training_set[training_set == 1 ] = 0\n",
        "training_set[training_set == 2] = 0\n",
        "training_set[training_set >= 3] = 1\n",
        "\n",
        "test_set[test_set == 0] = -1\n",
        "test_set[test_set == 1 ] = 0\n",
        "test_set[test_set == 2] = 0\n",
        "test_set[test_set >= 3] = 1"
      ],
      "metadata": {
        "id": "zHHXDxz3epVO"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Creating the Architecture of the Neural Network"
      ],
      "metadata": {
        "id": "5iDzBzcUev1s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RBM():\n",
        "  def __init__(self, nv, nh):\n",
        "    self.W = torch.randn(nh, nv)\n",
        "    self.a = torch.randn(1, nh)\n",
        "    self.b = torch.randn(1, nv)\n",
        "  def sample_h(self, x):\n",
        "    wx = torch.mm(x, self.W.t())\n",
        "    activation = wx + self.a.expand_as(wx)\n",
        "    p_h_given_v = torch.sigmoid(activation)\n",
        "    return p_h_given_v, torch.bernoulli(p_h_given_v)\n",
        "  def sample_v(self, y):\n",
        "    wy = torch.mm(y, self.W)\n",
        "    activation = wy + self.b.expand_as(wy)\n",
        "    p_v_given_h = torch.sigmoid(activation)\n",
        "    return p_v_given_h, torch.bernoulli(p_v_given_h)\n",
        "  def train(self, v0, vk, ph0, phk):\n",
        "    self.W += torch.mm(ph0.t(), v0) - torch.mm(phk.t(), vk)\n",
        "    self.b += torch.sum((v0 - vk), 0)\n",
        "    self.a += torch.sum((ph0 - phk), 0)"
      ],
      "metadata": {
        "id": "uVz8K7z3eyYi"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nv = len(training_set[0])\n",
        "nh = 100\n",
        "batch_size = 100\n",
        "rbm = RBM(nv, nh)"
      ],
      "metadata": {
        "id": "yL5lIK-De15p"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Training the RBM"
      ],
      "metadata": {
        "id": "Lcdusr7We5ci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nb_epoch = 10\n",
        "for epoch in range(1, nb_epoch + 1):\n",
        "    train_loss = 0\n",
        "    s = 0.\n",
        "    for id_user in range(0, nb_users - batch_size, batch_size):\n",
        "        vk = training_set[id_user:id_user+batch_size]\n",
        "        v0 = training_set[id_user:id_user+batch_size]\n",
        "        ph0,_ = rbm.sample_h(v0)\n",
        "        for k in range(10):\n",
        "            _,hk = rbm.sample_h(vk)\n",
        "            _,vk = rbm.sample_v(hk)\n",
        "            vk[v0<0] = v0[v0<0]\n",
        "        phk,_ = rbm.sample_h(vk)\n",
        "        rbm.train(v0, vk, ph0, phk)\n",
        "        train_loss += torch.mean(torch.abs(v0[v0>=0] - vk[v0>=0]))\n",
        "        s += 1.\n",
        "\n",
        "    print('epoch: '+str(epoch)+' loss: '+str(train_loss/s))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4AXs_X-e68B",
        "outputId": "7efe02e7-0b7e-491e-93ae-8d8f45a3a5f4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1 loss: tensor(0.3641)\n",
            "epoch: 2 loss: tensor(0.2625)\n",
            "epoch: 3 loss: tensor(0.2488)\n",
            "epoch: 4 loss: tensor(0.2489)\n",
            "epoch: 5 loss: tensor(0.2491)\n",
            "epoch: 6 loss: tensor(0.2511)\n",
            "epoch: 7 loss: tensor(0.2485)\n",
            "epoch: 8 loss: tensor(0.2499)\n",
            "epoch: 9 loss: tensor(0.2485)\n",
            "epoch: 10 loss: tensor(0.2476)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Testing the RBM"
      ],
      "metadata": {
        "id": "e5t-7Soze-Qo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating the RBM\n",
        "test_loss = 0\n",
        "s = 0.\n",
        "for id_user in range(nb_users):\n",
        "    v = training_set[id_user:id_user+1]\n",
        "    vt = test_set[id_user:id_user+1]\n",
        "    if len(vt[vt>=0]) > 0:\n",
        "        _,h = rbm.sample_h(v)\n",
        "        _,v = rbm.sample_v(h)\n",
        "        test_loss += torch.mean(torch.abs(vt[vt>=0] - v[vt>=0]))\n",
        "        s += 1.\n",
        "print('test loss: '+str(test_loss/s))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EhN4KVmrfBPP",
        "outputId": "839c3f78-576d-40ae-f956-a932ce0c5b2c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test loss: tensor(0.2360)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part 5 - Making Recommendations"
      ],
      "metadata": {
        "id": "hrowa6_mfJ0k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Making recommendations for a specific user\n",
        "user_id_to_recommend = 1 # You can change this to any user ID\n",
        "\n",
        "# Get the user's ratings from the training set\n",
        "user_ratings = training_set[user_id_to_recommend - 1 : user_id_to_recommend]\n",
        "\n",
        "# Get the predicted ratings for the user\n",
        "_, h = rbm.sample_h(user_ratings)\n",
        "predicted_ratings = rbm.sample_v(h)[0]\n",
        "\n",
        "# Identify movies the user hasn't rated (where the original rating is -1)\n",
        "unrated_movies_indices = (user_ratings < 0).nonzero(as_tuple=True)[1]\n",
        "\n",
        "# Get the predicted ratings for the unrated movies\n",
        "predicted_ratings_unrated = predicted_ratings[0][unrated_movies_indices]\n",
        "\n",
        "# Get the movie titles for the unrated movies\n",
        "unrated_movie_ids = unrated_movies_indices + 1\n",
        "unrated_movie_titles = movies[movies[0].isin(unrated_movie_ids)][1].values\n",
        "\n",
        "# Create a list of predicted ratings and movie titles for unrated movies\n",
        "recommendations = list(zip(unrated_movie_titles, predicted_ratings_unrated.tolist()))\n",
        "\n",
        "# Sort recommendations by predicted rating in descending order\n",
        "recommendations.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# Print the top recommendations\n",
        "print(f\"Top recommendations for User {user_id_to_recommend}:\")\n",
        "for title, rating in recommendations[:10]: # Print top 10 recommendations\n",
        "    print(f\"- {title}: {rating:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "niIzcv-CfKmO",
        "outputId": "27613f76-1cae-4bf6-e36e-ac102e0b434e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top recommendations for User 1:\n",
            "- Jade (1995): 0.99\n"
          ]
        }
      ]
    }
  ]
}